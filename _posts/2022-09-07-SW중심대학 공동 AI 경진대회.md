---
layout: post
title:  "SW중심대학 공동 AI 경진대회"
date:   2022-09-07
excerpt: "심리예측"
project: true
tag: [AI_reserch]
comments: true
---
![image](https://user-images.githubusercontent.com/70894372/188795855-c35a75ff-f79f-4c9c-af6b-596b51cea4bd.png)

2022년 여름방학 중 SW 중심대학협회에서 주최하는 SW중심대학 공동 AI 경진대회에 참가하였다. 

본 대회 예선은 "심리 성향 예측"을 주제로 진행되었다.

> Dataset 확인

대회측에서 제시한 데이터는 14999개의 Train Dataset와 35351개의 Test Dataset을 활용하여 nerdiness값을 예측한다.

```python
train.info()
```

```python
| index | Q1 | Q2 | Q3 | Q4 | Q5 | Q6 | Q7 | Q8 | Q9 | Q10 | Q11 | Q12  | Q13 | Q14 | Q15 | Q16 | Q17 | Q18 | Q19 | Q20 | Q21 | Q22 | Q23 | Q24 | Q25 | Q26 | country | introelapse | testelapse | surveyelapse | TIPI1 | TIPI2 | TIPI3 | TIPI4 | TIPI5 | TIPI6 | TIPI7 | TIPI8 | TIPI9 | TIPI10 | VCL1 | VCL2 | VCL3 | VCL4 | VCL5 | VCL6 | VCL7 | VCL8 | VCL9 | VCL10 | VCL11 | VCL12 | VCL13 | VCL14 | VCL15 | VCL16 | education | urban | gender | engnat | age | hand | religion | orientation | voted | married | familysize | ASD | nerdiness |
```

대회 시작과 동시에 Dataset이 공개되었다. Train Dataset은 69개의 특징과 1개(nerdiness)으로 이루어져 있었다. 

먼저 데이터를 확인해 보았지만 감이 잡히지 않았다. 각 index는 52개의 설문 특징과 과 16개의 인적사항 특징이 존재하였다. 

참고할만한 예제를 찾아보다 타이타닉 생존 예측 데이터와 심리 예측 데이터가 비슷하다는 것을 확인하였다. 

이를 통해 타이타닉 예제를 참고하여 본 문제를 풀어보면 좋겠다는 생각을 하게되었다.

하지만 타이타닉 예제들이 많고 다양한 알고리즘을 활요하여 이 문제에 적합한 알고리즘이 무엇인지 찾아내야했다.

> 데이터 파악

먼저 학습에 필요없는 index부터 제거하였다

```python
train = train.drop(['index'],axis = 1)
test = test.drop(['index'],axis = 1)
```

데이터를 파악하기 위해 먼저 Train Dataset과 Test Dataset의 결합을 진행하였다.

```python
#데이터 전처리를 위한 데이터 결합
all_data = pd.concat([train, test], axis=0)
print(all_data.shape)
all_data.head()
```

```python
(50452, 69)
```

데이터를 확인하고 결측값들을 최빈값으로 설정해 주었다.

```python
all_data.loc[all_data['gender'] == 0, 'gender'] = 2
all_data.loc[all_data['married'] == 0, 'married'] = 1
all_data.loc[all_data['ASD'] == 0, 'ASD'] = 2
all_data.loc[all_data['education'] == 0, 'education'] = all_data['education'].mode()[0]
all_data.loc[all_data['voted'] == 0, 'voted'] = all_data['voted'].mode()[0]
all_data.loc[all_data['urban'] == 0, 'urban'] = all_data['urban'].mode()[0]
all_data.loc[all_data['orientation'] == 0, 'orientation'] = all_data['orientation'].mode()[0]
all_data.loc[all_data['religion'] == 0, 'religion'] = all_data['religion'].mode()[0]
all_data.loc[all_data['engnat'] == 0, 'engnat'] = all_data['engnat'].mode()[0]
all_data.loc[all_data['hand'] == 0, 'hand'] = all_data['hand'].mode()[0]
all_data.loc[all_data['familysize'] > 7, 'familysize'] = all_data['familysize'].mode()[0]
all_data.loc[all_data['age'] > 100, 'age'] = all_data['familysize'].mode()[0]
all_data.loc[all_data['Q1'] == 0, 'Q1'] = all_data['Q1'].mode()[0]
all_data.loc[all_data['Q2'] == 0, 'Q2'] = all_data['Q2'].mode()[0]
all_data.loc[all_data['Q3'] == 0, 'Q3'] = all_data['Q3'].mode()[0]
all_data.loc[all_data['Q4'] == 0, 'Q4'] = all_data['Q4'].mode()[0]
all_data.loc[all_data['Q5'] == 0, 'Q5'] = all_data['Q5'].mode()[0]
all_data.loc[all_data['Q6'] == 0, 'Q6'] = all_data['Q6'].mode()[0]
all_data.loc[all_data['Q7'] == 0, 'Q7'] = all_data['Q7'].mode()[0]
all_data.loc[all_data['Q8'] == 0, 'Q8'] = all_data['Q8'].mode()[0]
all_data.loc[all_data['Q9'] == 0, 'Q9'] = all_data['Q9'].mode()[0]
all_data.loc[all_data['Q10'] == 0, 'Q10'] = all_data['Q10'].mode()[0]
all_data.loc[all_data['Q11'] == 0, 'Q11'] = all_data['Q11'].mode()[0]
all_data.loc[all_data['Q12'] == 0, 'Q12'] = all_data['Q12'].mode()[0]
all_data.loc[all_data['Q13'] == 0, 'Q13'] = all_data['Q13'].mode()[0]
all_data.loc[all_data['Q14'] == 0, 'Q14'] = all_data['Q14'].mode()[0]
all_data.loc[all_data['Q15'] == 0, 'Q15'] = all_data['Q15'].mode()[0]
all_data.loc[all_data['Q16'] == 0, 'Q16'] = all_data['Q16'].mode()[0]
all_data.loc[all_data['Q17'] == 0, 'Q17'] = all_data['Q17'].mode()[0]
all_data.loc[all_data['Q18'] == 0, 'Q18'] = all_data['Q18'].mode()[0]
all_data.loc[all_data['Q19'] == 0, 'Q19'] = all_data['Q19'].mode()[0]
all_data.loc[all_data['Q20'] == 0, 'Q20'] = all_data['Q20'].mode()[0]
all_data.loc[all_data['Q21'] == 0, 'Q21'] = all_data['Q21'].mode()[0]
all_data.loc[all_data['Q22'] == 0, 'Q22'] = all_data['Q22'].mode()[0]
all_data.loc[all_data['Q23'] == 0, 'Q23'] = all_data['Q23'].mode()[0]
all_data.loc[all_data['Q24'] == 0, 'Q24'] = all_data['Q24'].mode()[0]
all_data.loc[all_data['Q25'] == 0, 'Q25'] = all_data['Q25'].mode()[0]
all_data.loc[all_data['Q26'] == 0, 'Q26'] = all_data['Q26'].mode()[0]
```


데이터 전처리 후 다시 train과 test로 데이터를 분리해 주었다.
```python
train = all_data.iloc[:train.shape[0]]
test = all_data.iloc[train.shape[0]:]
print(train)
```

country도 맵핑을통해 각 숫자들로 매칭을 시켜주었다.
```python
country_map = {i: c for c, i in enumerate(all_data['country'].unique())}

train['country'] = train['country'].map(country_map)
test['country'] = test['country'].map(country_map)
```

데이터들의 결측값 유무를 확인하여 더이상 결측값은 측정되지 않았다.
```python
print(pd.DataFrame(train.isnull().sum()))
print(pd.DataFrame(test.isnull().sum()))
```

RandomForestClassifier과 LGBMClassifier을 사용하여 학습을 진행한다.
```python
X_train, X_test, y_train, y_test =\
    train_test_split(x_train, y_train, test_size=0.3, random_state=2020)
```

RandomForestClassifier 학습모델 구축
```python
rf_clf = RandomForestClassifier(n_estimators=700)
rf_clf.fit(X_train, y_train)
rf_pred = rf_clf.predict_proba(X_test)[:, 1]
roc_auc_score(y_test, rf_pred)
```

LGBMClassifier 학습모델 구축
```python
lgbm_clf = LGBMClassifier(
            n_estimators=10000,
            learning_rate=0.01,
            random_state=100,
            max_depth=10,
            num_leaves=600,
            min_child_samples=10,
            subsample=0.80,
            colsample_bytree=0.50,
            max_bin=450,
            reg_lambda=0.07,
            reg_alpha=0.28
        )

lgbm_clf.fit(X_train, y_train)
lgbm_pred = lgbm_clf.predict_proba(X_test)[:, 1]
roc_auc_score(y_test, lgbm_pred)
```
비중 설정 : RandomForestClassifier 70% 설정, LGBMClassifier 30% 설정
```python
y_preds = 0.3 * lgbm_pred + 0.7 * rf_pred
roc_auc_score(y_test, y_preds)
```

```python
lgbm_clf.fit(train, target)
lgbm_pred = lgbm_clf.predict_proba(test)[:, 1]
rf_clf.fit(train, target)
rf_pred = rf_clf.predict_proba(test)[:, 1]
y_pred = 0.4 * lgbm_pred + 0.6 * rf_pred
submission['nerdiness'] = y_pred
submission.to_csv('test.csv', index=False)
```

![image](https://user-images.githubusercontent.com/70894372/189823428-1de4841d-e562-44c0-8db5-24a086f45837.png)

결과는 90.093%로 21위를 기록하고 대회를 마무리 하였다.

본 대회는 총 724명이 참가하고 192팀으로 구성되었다.